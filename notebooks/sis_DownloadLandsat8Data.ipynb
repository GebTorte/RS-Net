{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import urllib\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Products found: 96\n",
      "Example url:    https://landsat.usgs.gov/cloud-validation/cca_l8/LC80420082013220LGN00.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# Get the webpage\n",
    "url = 'https://landsat.usgs.gov/landsat-8-cloud-cover-assessment-validation-data'\n",
    "response = urllib.request.urlopen(url)\n",
    "\n",
    "# Find the data urls in the source\n",
    "data_urls = []\n",
    "for line in response:\n",
    "    if 'https://landsat.usgs.gov/cloud-validation/cca' in str(line) and 'tar' in str(line):        \n",
    "        data_urls.append(str(line)[47:124])\n",
    "\n",
    "print(\"Products found:\", np.size(data_urls))\n",
    "print(\"Example url:   \", data_urls[0])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define backgrounds\n",
    "backgrounds = ['Barren',\n",
    "               'Forest',\n",
    "               'GrassCrops',\n",
    "               'Shrubland',\n",
    "               'SnowIce',\n",
    "               'Urban',\n",
    "               'Water',\n",
    "               'Wetlands']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "last_percent_decimal_step = 0.0\n",
    "\n",
    "# only use for synchronous download (global variable might lead to lags)\n",
    "def rep_hoo(current_block_count, block_size, total_size):\n",
    "    percentage = current_block_count*block_size/total_size*100\n",
    "    \n",
    "    global last_percent_decimal_step \n",
    "    if abs(percentage - last_percent_decimal_step) >= 1.0 or percentage==100.0:\n",
    "        last_percent_decimal_step = percentage\n",
    "        print(f\"Download at {percentage:.1f}% - {current_block_count} blocks of {total_size//block_size} total blocks\")\n",
    "        clear_output(wait=True)\n",
    "\n",
    "def async_report_hook(current_block_count, block_size, total_size):\n",
    "    percentage = current_block_count*block_size/total_size*100\n",
    "    if percentage%1==0 or percentage==100.0:\n",
    "        print(f\"Download at {percentage:.1f}% - {current_block_count} blocks of {total_size//block_size} total blocks\")\n",
    "        clear_output()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Synchronous Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m12\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:  \u001b[38;5;66;03m# There are 12 scenes in every background category       \u001b[39;00m\n\u001b[0;32m      6\u001b[0m     index \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m     \n\u001b[1;32m----> 7\u001b[0m (txt, httpmsg) \u001b[38;5;241m=\u001b[39m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_urls\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./tar/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mbackgrounds\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mdata_urls\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreporthook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrep_hoo\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\anaconda3\\envs\\satellite-ml\\lib\\urllib\\request.py:268\u001b[0m, in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[0;32m    265\u001b[0m     reporthook(blocknum, bs, size)\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 268\u001b[0m     block \u001b[38;5;241m=\u001b[39m \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    269\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m block:\n\u001b[0;32m    270\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mf:\\anaconda3\\envs\\satellite-ml\\lib\\http\\client.py:463\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    461\u001b[0m     \u001b[38;5;66;03m# Amount is given, implement using readinto\u001b[39;00m\n\u001b[0;32m    462\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytearray\u001b[39m(amt)\n\u001b[1;32m--> 463\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(b)[:n]\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[0;32m    465\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    466\u001b[0m     \u001b[38;5;66;03m# Amount is not given (unbounded read) so we must check self.length\u001b[39;00m\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;66;03m# and self.chunked\u001b[39;00m\n",
      "File \u001b[1;32mf:\\anaconda3\\envs\\satellite-ml\\lib\\http\\client.py:507\u001b[0m, in \u001b[0;36mHTTPResponse.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    502\u001b[0m         b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmemoryview\u001b[39m(b)[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength]\n\u001b[0;32m    504\u001b[0m \u001b[38;5;66;03m# we do not use _safe_read() here because this may be a .will_close\u001b[39;00m\n\u001b[0;32m    505\u001b[0m \u001b[38;5;66;03m# connection, and the user is reading more bytes than will be provided\u001b[39;00m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# (for example, reading in 1k chunks)\u001b[39;00m\n\u001b[1;32m--> 507\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m n \u001b[38;5;129;01mand\u001b[39;00m b:\n\u001b[0;32m    509\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[0;32m    510\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[1;32mf:\\anaconda3\\envs\\satellite-ml\\lib\\socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mf:\\anaconda3\\envs\\satellite-ml\\lib\\ssl.py:1275\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1271\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1272\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1273\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1274\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1276\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mf:\\anaconda3\\envs\\satellite-ml\\lib\\ssl.py:1133\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1134\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1135\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "index = -1 # index -1\n",
    "for i in range(0, np.size(data_urls)): # range(0, np.size(data_urls))\n",
    "    if i%12 == 0:  # There are 12 scenes in every background category\n",
    "        index += 1\n",
    "        if not os.path.exists(os.getcwd()+\"/tar/\"+backgrounds[index]+\"/\"):\n",
    "            os.mkdir(os.getcwd()+\"/tar/\"+backgrounds[index]+\"/\")\n",
    "    print(\"Downloading file \" + data_urls[i].split(\"/\")[-1])\n",
    "    (txt, httpmsg) = urllib.request.urlretrieve(data_urls[i], os.getcwd()+\"/tar/\"+backgrounds[index]+\"/\"+data_urls[i].split(\"/\")[-1], reporthook=rep_hoo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asynchronous Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "\n",
    "async def download_tar_by_url_in_thread(url, background):\n",
    "    loop = asyncio.get_event_loop()\n",
    "    path = os.getcwd()+\"/tar/\"+background+\"/\"+url.split(\"/\")[-1]\n",
    "    future = loop.run_in_executor(None, urllib.request.urlretrieve, url, path, async_report_hook)\n",
    "    response, headers = await future\n",
    "\n",
    "async def download_tar_by_url(session, url, background):\n",
    "    # https://www.slingacademy.com/article/python-aiohttp-how-to-download-files-using-streams/\n",
    "    # !! chunks often corrupted\n",
    "    async with session.get(url) as response:\n",
    "        assert response.status == 200\n",
    "        filename=url.split(\"/\")[-1]\n",
    "        path = f\"./tar/{background}/{filename}\"\n",
    "        with open(path, 'wb') as file:\n",
    "            while True:\n",
    "                chunk = await response.content.readany()\n",
    "                if not chunk:\n",
    "                    break\n",
    "                file.write(chunk)\n",
    "        print(f\"Downloaded {url} to {path}\")\n",
    "    #urllib.request.urlretrieve(data_urls[i], os.getcwd()+\"/tar/\"+backgrounds[index]+\"/\"+data_urls[i].split(\"/\")[-1], reporthook=rep_hoo)\n",
    "    #return await subprocess.Popen(f\"wget {url} -P {'./tar/' + background + '/'}\")\n",
    "    #return await os.system(f\"wget {url} -P {'./tar/' + background + '/'}\")\n",
    "\n",
    "async def download_bulk_urllib(urls, backgrounds):\n",
    "    tasks = [download_tar_by_url_in_thread(url, bg) for url, bg in zip(urls, backgrounds)]\n",
    "    await asyncio.gather(*tasks)\n",
    "\n",
    "async def download_bulk(urls, backgrounds):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = [download_tar_by_url(session, url, bg) for url, bg in zip(urls, backgrounds)]\n",
    "        await asyncio.gather(*tasks)\n",
    "\n",
    "async def download_all(start=0, folder_size=12):\n",
    "    for i in range(start, np.size(data_urls)):\n",
    "        if i%12==0:\n",
    "            bg = backgrounds[i//folder_size]\n",
    "            if not os.path.exists(os.getcwd()+\"/tar/\"+bg):\n",
    "                os.mkdir(os.getcwd()+\"/tar/\"+bg)\n",
    "            await download_bulk_urllib(urls=[data_urls[j] for j in range(i, i+folder_size)], backgrounds=[bg]*folder_size)\n",
    "\n",
    "async def download_all_v2(start=0, end=0, folder_size=12):\n",
    "    # pass <np.size(data_urls)> as end for download all\n",
    "    bulk = []\n",
    "    bgs = []\n",
    "    for i in range(start, end):\n",
    "        if i%folder_size == 0:\n",
    "            bg = backgrounds[i//folder_size]\n",
    "            if not os.path.exists(os.getcwd()+\"/tar/\"+bg):\n",
    "                    os.mkdir(\"./tar/\"+bg)\n",
    "        bulk.append(data_urls[i])\n",
    "        bgs.append(bg)    \n",
    "    await download_bulk_urllib(urls=bulk, backgrounds=bgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download at 0.0% - 0 blocks of 130115 total blocks\n"
     ]
    }
   ],
   "source": [
    "%autoawait asyncio\n",
    "\n",
    "# v2 fastest option (so far) with 24m 55.5s at ~40-70MBps and with threadcount 70\n",
    "await download_all_v2(end=np.size(data_urls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other possible (not implemented) options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all the products\n",
    "# index = -1\n",
    "# for i in range(0, np.size(data_urls)):\n",
    "#     if i%12 == 0:  # There are 12 scenes in every background category       \n",
    "#         index += 1     \n",
    "#     !wget {data_urls[i]+'.tar.gz'} -P {'./tar/' + backgrounds[index] + '/'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.gnu.org/software/parallel/man.html#example__download_10_images_for_each_of_the_past_30_days\n",
    "\n",
    "Running 10000 jobs with 100 in parallel:\n",
    "> seq 10000 | parallel -j100 wget https://www.example.com/page{}.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all the products in background\n",
    "#index = -1\n",
    "#for i in range(0, np.size(data_urls)):\n",
    "    # if i%12 == 0:  # There are 12 scenes in every background category       \n",
    "    #     index += 1\n",
    "    # !wget -b {data_urls[i]+'.tar.gz'} -P {'./tar/' + backgrounds[index] + '/'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unzipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "Unzipping product: LC80420082013220LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80500092014231LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80530022014156LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81330312013202LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81360302014162LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81390292014135LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81550082014263LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81570452014213LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81640502013179LGN01.tar.gz\n",
      "----\n",
      "Unzipping product: LC81750432013144LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81930452013126LGN01.tar.gz\n",
      "----\n",
      "Unzipping product: LC81990402014267LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80310202013223LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80340192014167LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81010142014189LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81020152014036LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81030162014107LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81070152013260LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81080162013171LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81080182014238LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81460162014168LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81500152013225LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81580172013201LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81750732014035LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80070662014234LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80160502014041LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80200462014005LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80500172014247LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81170272014189LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81310182013108LGN01.tar.gz\n",
      "----\n",
      "Unzipping product: LC81330182013186LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81720192013331LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81750622013304LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81800662014230LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC82290572014141LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC82310592014139LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80150312014226LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80170312013157LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80410372013357LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80460282014171LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80640452014041LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81180382014244LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81620432014072LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81660432014020LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81770262013254LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81920192013103LGN01.tar.gz\n",
      "----\n",
      "Unzipping product: LC81940222013245LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81970242013218LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80010732013109LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80320382013278LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80350192014190LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80630152013207LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80670172014206LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80750172013163LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80760182013170LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80980762014216LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81020802014100LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81490122013218LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81590362014051LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81600462013215LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80290292014132LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80290372013257LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80980712014024LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81220312014208LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81220422014096LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81320352013243LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81440462014250LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81490432014141LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81510262014139LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81750512013208LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81820302014180LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC82020522013141LGN01.tar.gz\n",
      "----\n",
      "Unzipping product: LC80120552013202LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80180082014215LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80210072014236LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80430122014214LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80650182013237LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81040622014066LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81130632014241LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81240462014238LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81620582014104LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81660032014196LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81910182013240LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC82150712013152LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80010112014080LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80060102014147LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80211222013361LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80250022014232LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80441162013330LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80841202014309LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81001082014022LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81321192014054LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC82001192013335LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC82171112014297LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC82271192014287LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC82320072014226LGN00.tar.gz\n"
     ]
    }
   ],
   "source": [
    "from shutil import unpack_archive\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "folders = [i for i in os.listdir(\"./tar/\") if i not in [\".gitignore\", \".gitkeep\"]]\n",
    "\n",
    "for folder in folders:\n",
    "    Path(\"./unzipped/\" + folder).mkdir(parents=True, exist_ok=True)\n",
    "    files = sorted(os.listdir(\"tar/\" + folder))\n",
    "    files = [f for f in files if '.tar.gz' in f] \n",
    "    for file in files:\n",
    "        try: \n",
    "            print(\"----\")\n",
    "            print(\"Unzipping product:\", file)\n",
    "\n",
    "            unpack_archive(f\"./tar/{folder}/{file}\", f\"./unzipped/{folder}\")\n",
    "        except:\n",
    "            print(\"----------------------------------------------------\")\n",
    "            print(\"UNZIP ERROR WITH PRODUCT:\", file)\n",
    "            pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "satellite-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
