{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import urllib\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Products found: 96\n",
      "Example url:    https://landsat.usgs.gov/cloud-validation/cca_l8/LC80420082013220LGN00.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# Get the webpage\n",
    "url = 'https://landsat.usgs.gov/landsat-8-cloud-cover-assessment-validation-data'\n",
    "response = urllib.request.urlopen(url)\n",
    "\n",
    "# Find the data urls in the source\n",
    "data_urls = []\n",
    "for line in response:\n",
    "    if 'https://landsat.usgs.gov/cloud-validation/cca' in str(line) and 'tar' in str(line):        \n",
    "        data_urls.append(str(line)[47:124])\n",
    "\n",
    "print(\"Products found:\", np.size(data_urls))\n",
    "print(\"Example url:   \", data_urls[0])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define backgrounds\n",
    "backgrounds = ['Barren',\n",
    "               'Forest',\n",
    "               'GrassCrops',\n",
    "               'Shrubland',\n",
    "               'SnowIce',\n",
    "               'Urban',\n",
    "               'Water',\n",
    "               'Wetlands']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "last_percent_decimal_step = 0.0\n",
    "\n",
    "# only use for synchronous download (global variable might lead to lags)\n",
    "def rep_hoo(current_block_count, block_size, total_size):\n",
    "    percentage = current_block_count*block_size/total_size*100\n",
    "    \n",
    "    global last_percent_decimal_step \n",
    "    if abs(percentage - last_percent_decimal_step) >= 1.0 or percentage==100.0:\n",
    "        last_percent_decimal_step = percentage\n",
    "        print(f\"Download at {percentage:.1f}% - {current_block_count} blocks of {total_size//block_size} total blocks\")\n",
    "        clear_output(wait=True)\n",
    "\n",
    "def async_report_hook(current_block_count, block_size, total_size):\n",
    "    percentage = current_block_count*block_size/total_size*100\n",
    "    if percentage%1==0 or percentage==100.0:\n",
    "        print(f\"Download at {percentage:.1f}% - {current_block_count} blocks of {total_size//block_size} total blocks\")\n",
    "        clear_output()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Synchronous Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m12\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:  \u001b[38;5;66;03m# There are 12 scenes in every background category       \u001b[39;00m\n\u001b[0;32m      6\u001b[0m     index \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m     \n\u001b[1;32m----> 7\u001b[0m (txt, httpmsg) \u001b[38;5;241m=\u001b[39m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_urls\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./tar/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mbackgrounds\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mdata_urls\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreporthook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrep_hoo\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\anaconda3\\envs\\satellite-ml\\lib\\urllib\\request.py:268\u001b[0m, in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[0;32m    265\u001b[0m     reporthook(blocknum, bs, size)\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 268\u001b[0m     block \u001b[38;5;241m=\u001b[39m \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    269\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m block:\n\u001b[0;32m    270\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mf:\\anaconda3\\envs\\satellite-ml\\lib\\http\\client.py:463\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    461\u001b[0m     \u001b[38;5;66;03m# Amount is given, implement using readinto\u001b[39;00m\n\u001b[0;32m    462\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytearray\u001b[39m(amt)\n\u001b[1;32m--> 463\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(b)[:n]\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[0;32m    465\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    466\u001b[0m     \u001b[38;5;66;03m# Amount is not given (unbounded read) so we must check self.length\u001b[39;00m\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;66;03m# and self.chunked\u001b[39;00m\n",
      "File \u001b[1;32mf:\\anaconda3\\envs\\satellite-ml\\lib\\http\\client.py:507\u001b[0m, in \u001b[0;36mHTTPResponse.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    502\u001b[0m         b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmemoryview\u001b[39m(b)[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength]\n\u001b[0;32m    504\u001b[0m \u001b[38;5;66;03m# we do not use _safe_read() here because this may be a .will_close\u001b[39;00m\n\u001b[0;32m    505\u001b[0m \u001b[38;5;66;03m# connection, and the user is reading more bytes than will be provided\u001b[39;00m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# (for example, reading in 1k chunks)\u001b[39;00m\n\u001b[1;32m--> 507\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m n \u001b[38;5;129;01mand\u001b[39;00m b:\n\u001b[0;32m    509\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[0;32m    510\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[1;32mf:\\anaconda3\\envs\\satellite-ml\\lib\\socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mf:\\anaconda3\\envs\\satellite-ml\\lib\\ssl.py:1275\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1271\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1272\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1273\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1274\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1276\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mf:\\anaconda3\\envs\\satellite-ml\\lib\\ssl.py:1133\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1134\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1135\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "index = -1 # index -1\n",
    "for i in range(0, np.size(data_urls)): # range(0, np.size(data_urls))\n",
    "    if i%12 == 0:  # There are 12 scenes in every background category\n",
    "        index += 1\n",
    "        if not os.path.exists(os.getcwd()+\"/tar/\"+backgrounds[index]+\"/\"):\n",
    "            os.mkdir(os.getcwd()+\"/tar/\"+backgrounds[index]+\"/\")\n",
    "    print(\"Downloading file \" + data_urls[i].split(\"/\")[-1])\n",
    "    (txt, httpmsg) = urllib.request.urlretrieve(data_urls[i], os.getcwd()+\"/tar/\"+backgrounds[index]+\"/\"+data_urls[i].split(\"/\")[-1], reporthook=rep_hoo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asynchronous Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "async def download_tar_by_url_in_thread(url, background):\n",
    "    # this will default the workers to #processors on your machine *5\n",
    "    # https://stackoverflow.com/questions/75885213/how-to-increase-asyncio-thread-limits-in-an-existing-co-routine\n",
    "    loop = asyncio.get_event_loop()\n",
    "    path = os.getcwd()+\"/tar/\"+background+\"/\"+url.split(\"/\")[-1]\n",
    "    future = loop.run_in_executor(None, urllib.request.urlretrieve, url, path, async_report_hook)\n",
    "    response, headers = await future\n",
    "\n",
    "async def download_tar_by_url_in_thread_with_limit(url, background, limit_workers=40):\n",
    "    # this creates a custom ThreadPoolExecutor with default worker limit of 40\n",
    "    loop = asyncio.get_event_loop()\n",
    "    path = os.getcwd()+\"/tar/\"+background+\"/\"+url.split(\"/\")[-1]\n",
    "    future = loop.run_in_executor(ThreadPoolExecutor(max_workers=limit_workers), urllib.request.urlretrieve, url, path, async_report_hook)\n",
    "    response, headers = await future\n",
    "\n",
    "async def download_tar_by_url(session, url, background):\n",
    "    # https://www.slingacademy.com/article/python-aiohttp-how-to-download-files-using-streams/\n",
    "    # !! chunks often corrupted\n",
    "    async with session.get(url) as response:\n",
    "        assert response.status == 200\n",
    "        filename=url.split(\"/\")[-1]\n",
    "        path = f\"./tar/{background}/{filename}\"\n",
    "        with open(path, 'wb') as file:\n",
    "            while True:\n",
    "                chunk = await response.content.readany()\n",
    "                if not chunk:\n",
    "                    break\n",
    "                file.write(chunk)\n",
    "        print(f\"Downloaded {url} to {path}\")\n",
    "    #urllib.request.urlretrieve(data_urls[i], os.getcwd()+\"/tar/\"+backgrounds[index]+\"/\"+data_urls[i].split(\"/\")[-1], reporthook=rep_hoo)\n",
    "    #return await subprocess.Popen(f\"wget {url} -P {'./tar/' + background + '/'}\")\n",
    "    #return await os.system(f\"wget {url} -P {'./tar/' + background + '/'}\")\n",
    "\n",
    "async def download_bulk_urllib(urls, backgrounds):\n",
    "    tasks = [download_tar_by_url_in_thread(url, bg) for url, bg in zip(urls, backgrounds)]\n",
    "    await asyncio.gather(*tasks)\n",
    "\n",
    "async def download_bulk(urls, backgrounds):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = [download_tar_by_url(session, url, bg) for url, bg in zip(urls, backgrounds)]\n",
    "        await asyncio.gather(*tasks)\n",
    "\n",
    "async def download_all(start=0, folder_size=12):\n",
    "    for i in range(start, np.size(data_urls)):\n",
    "        if i%12==0:\n",
    "            bg = backgrounds[i//folder_size]\n",
    "            if not os.path.exists(os.getcwd()+\"/tar/\"+bg):\n",
    "                os.mkdir(os.getcwd()+\"/tar/\"+bg)\n",
    "            await download_bulk_urllib(urls=[data_urls[j] for j in range(i, i+folder_size)], backgrounds=[bg]*folder_size)\n",
    "\n",
    "async def download_all_v2(start=0, end=0, folder_size=12):\n",
    "    # pass <np.size(data_urls)> as end for download all\n",
    "    bulk = []\n",
    "    bgs = []\n",
    "    for i in range(start, end):\n",
    "        if i%folder_size == 0:\n",
    "            bg = backgrounds[i//folder_size]\n",
    "            if not os.path.exists(os.getcwd()+\"/tar/\"+bg):\n",
    "                    os.mkdir(\"./tar/\"+bg)\n",
    "        bulk.append(data_urls[i])\n",
    "        bgs.append(bg)    \n",
    "    await download_bulk_urllib(urls=bulk, backgrounds=bgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ContentTooShortError",
     "evalue": "<urlopen error retrieval incomplete: got only 500935805 out of 932439747 bytes>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mContentTooShortError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mautoawait\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124masyncio\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# v2 fastest option (so far) with 24m 55.5s at ~40-70MBps and with threadcount 70\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m download_all_v2(end\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39msize(data_urls))\n",
      "Cell \u001b[0;32mIn[23], line 63\u001b[0m, in \u001b[0;36mdownload_all_v2\u001b[0;34m(start, end, folder_size)\u001b[0m\n\u001b[1;32m     61\u001b[0m     bulk\u001b[38;5;241m.\u001b[39mappend(data_urls[i])\n\u001b[1;32m     62\u001b[0m     bgs\u001b[38;5;241m.\u001b[39mappend(bg)    \n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m download_bulk_urllib(urls\u001b[38;5;241m=\u001b[39mbulk, backgrounds\u001b[38;5;241m=\u001b[39mbgs)\n",
      "Cell \u001b[0;32mIn[23], line 37\u001b[0m, in \u001b[0;36mdownload_bulk_urllib\u001b[0;34m(urls, backgrounds)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdownload_bulk_urllib\u001b[39m(urls, backgrounds):\n\u001b[1;32m     36\u001b[0m     tasks \u001b[38;5;241m=\u001b[39m [download_tar_by_url_in_thread_with_limit(url, bg) \u001b[38;5;28;01mfor\u001b[39;00m url, bg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(urls, backgrounds)]\n\u001b[0;32m---> 37\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39mtasks)\n",
      "Cell \u001b[0;32mIn[23], line 15\u001b[0m, in \u001b[0;36mdownload_tar_by_url_in_thread_with_limit\u001b[0;34m(url, background, limit_workers)\u001b[0m\n\u001b[1;32m     13\u001b[0m path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetcwd()\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/tar/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mbackground\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39murl\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     14\u001b[0m future \u001b[38;5;241m=\u001b[39m loop\u001b[38;5;241m.\u001b[39mrun_in_executor(ThreadPoolExecutor(max_workers\u001b[38;5;241m=\u001b[39mlimit_workers), urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlretrieve, url, path, async_report_hook)\n\u001b[0;32m---> 15\u001b[0m response, headers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m future\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m/usr/lib/python3.10/urllib/request.py:280\u001b[0m, in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    277\u001b[0m                 reporthook(blocknum, bs, size)\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m read \u001b[38;5;241m<\u001b[39m size:\n\u001b[0;32m--> 280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ContentTooShortError(\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mretrieval incomplete: got only \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m out of \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m bytes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m         \u001b[38;5;241m%\u001b[39m (read, size), result)\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mContentTooShortError\u001b[0m: <urlopen error retrieval incomplete: got only 500935805 out of 932439747 bytes>"
     ]
    }
   ],
   "source": [
    "%autoawait asyncio\n",
    "\n",
    "# v2 with download_tar_by_url_in_thread, threadcount 70, 24m 55.5s at ~40-70MBps\n",
    "# v2 with download_tar_by_url_in_thread_with_limit(..., limit_workers=40), threadcount 166, <time> at ~70MBps\n",
    "await download_all_v2(end=np.size(data_urls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other possible (not implemented) options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all the products\n",
    "# index = -1\n",
    "# for i in range(0, np.size(data_urls)):\n",
    "#     if i%12 == 0:  # There are 12 scenes in every background category       \n",
    "#         index += 1     \n",
    "#     !wget {data_urls[i]+'.tar.gz'} -P {'./tar/' + backgrounds[index] + '/'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.gnu.org/software/parallel/man.html#example__download_10_images_for_each_of_the_past_30_days\n",
    "\n",
    "Running 10000 jobs with 100 in parallel:\n",
    "> seq 10000 | parallel -j100 wget https://www.example.com/page{}.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all the products in background\n",
    "#index = -1\n",
    "#for i in range(0, np.size(data_urls)):\n",
    "    # if i%12 == 0:  # There are 12 scenes in every background category       \n",
    "    #     index += 1\n",
    "    # !wget -b {data_urls[i]+'.tar.gz'} -P {'./tar/' + backgrounds[index] + '/'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unzipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "Unzipping product: LC80420082013220LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80500092014231LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80530022014156LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81330312013202LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81360302014162LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81390292014135LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81550082014263LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81570452014213LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81640502013179LGN01.tar.gz\n",
      "----\n",
      "Unzipping product: LC81750432013144LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81930452013126LGN01.tar.gz\n",
      "----\n",
      "Unzipping product: LC81990402014267LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80310202013223LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80340192014167LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81010142014189LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81020152014036LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81030162014107LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81070152013260LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81080162013171LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81080182014238LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81460162014168LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81500152013225LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81580172013201LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81750732014035LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80070662014234LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80160502014041LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80200462014005LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80500172014247LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81170272014189LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81310182013108LGN01.tar.gz\n",
      "----\n",
      "Unzipping product: LC81330182013186LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81720192013331LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81750622013304LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81800662014230LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC82290572014141LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC82310592014139LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80150312014226LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80170312013157LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80410372013357LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80460282014171LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80640452014041LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81180382014244LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81620432014072LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81660432014020LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81770262013254LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81920192013103LGN01.tar.gz\n",
      "----\n",
      "Unzipping product: LC81940222013245LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81970242013218LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80010732013109LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80320382013278LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80350192014190LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80630152013207LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80670172014206LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80750172013163LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80760182013170LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80980762014216LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81020802014100LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81490122013218LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81590362014051LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81600462013215LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80290292014132LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80290372013257LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80980712014024LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81220312014208LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81220422014096LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81320352013243LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81440462014250LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81490432014141LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81510262014139LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81750512013208LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81820302014180LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC82020522013141LGN01.tar.gz\n",
      "----\n",
      "Unzipping product: LC80120552013202LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80180082014215LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80210072014236LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80430122014214LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80650182013237LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81040622014066LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81130632014241LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81240462014238LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81620582014104LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81660032014196LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81910182013240LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC82150712013152LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80010112014080LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80060102014147LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80211222013361LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80250022014232LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80441162013330LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC80841202014309LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81001082014022LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC81321192014054LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC82001192013335LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC82171112014297LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC82271192014287LGN00.tar.gz\n",
      "----\n",
      "Unzipping product: LC82320072014226LGN00.tar.gz\n"
     ]
    }
   ],
   "source": [
    "from shutil import unpack_archive\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "folders = [i for i in os.listdir(\"./tar/\") if i not in [\".gitignore\", \".gitkeep\"]]\n",
    "\n",
    "for folder in folders:\n",
    "    Path(\"./unzipped/\" + folder).mkdir(parents=True, exist_ok=True)\n",
    "    files = sorted(os.listdir(\"tar/\" + folder))\n",
    "    files = [f for f in files if '.tar.gz' in f] \n",
    "    for file in files:\n",
    "        try: \n",
    "            print(\"----\")\n",
    "            print(\"Unzipping product:\", file)\n",
    "\n",
    "            unpack_archive(f\"./tar/{folder}/{file}\", f\"./unzipped/{folder}\")\n",
    "        except:\n",
    "            print(\"----------------------------------------------------\")\n",
    "            print(\"UNZIP ERROR WITH PRODUCT:\", file)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the .img masks to .TIF masks (all systems) (must have gdal installed in py environment)\n",
    "from osgeo.gdal import Translate, TranslateOptions\n",
    "format = \"GTiff\"\n",
    "\n",
    "folders = sorted(os.listdir(\"./unzipped/\"))\n",
    "folders = [f for f in folders if '.' not in f]  # Filter out .gitignore\n",
    "for folder in folders[1:2]:\n",
    "    products = sorted(os.listdir(\"./unzipped/\" + folder + \"/BC/\"))\n",
    "    for product in products[1:2]:\n",
    "        img_path  = \"./unzipped/\" + folder + \"/BC/\" + product + \"/\" + product + \"_fixedmask.img\"\n",
    "        gtiff_path = \"./unzipped/\" + folder + \"/BC/\" + product + \"/\" + product + \"_fixedmask123.TIF\"\n",
    "        Translate(gtiff_path, img_path, **{\"format\": format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input file size is 8911, 8941\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 8671, 8721\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 9101, 9071\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 7611, 7751\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 7871, 7991\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 7781, 7901\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 8931, 8961\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 7551, 7721\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 7551, 7741\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 7571, 7391\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 7511, 7321\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 7691, 7851\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 7601, 7751\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 7541, 7721\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 7701, 7861\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 8061, 8151\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 7881, 8001\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 7881, 7681\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 8211, 8291\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 8241, 8321\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 7591, 7751\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 7641, 7791\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 7581, 7751\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 7601, 7771\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 7661, 7791\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 7741, 7881\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 7661, 7791\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 7671, 7811\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 7741, 7901\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 7591, 7731\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 7681, 7851\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 7741, 7891\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 7781, 7901\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 7551, 7731\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 7811, 7951\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 7471, 7291\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 7561, 7311\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 7681, 7831\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 8141, 8221\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 8161, 8241\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 8211, 8281\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 8081, 7881\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 8171, 7991\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 7651, 7771\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 7621, 7721\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 8541, 8601\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 7581, 7731\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 7711, 7871\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 8491, 8561\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 8581, 8641\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 7521, 7601\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 8961, 8941\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 9101, 9101\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 8121, 8061\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 9281, 9271\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 6611, 6711\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 8061, 7991\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 9201, 9191\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 8761, 8801\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 8891, 8931\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 7821, 7951\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 7561, 7351\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 7761, 7911\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 7791, 7911\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 7551, 7731\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 7721, 7871\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 7581, 7751\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 7591, 7761\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 8041, 8141\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 7791, 7571\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 8151, 8241\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 8081, 8181\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 7581, 7751\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 8871, 8911\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 9021, 9041\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 8441, 8511\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 8021, 8111\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 7591, 7761\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 7591, 7751\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 7641, 7811\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 7581, 7751\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 9161, 9161\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 8191, 8271\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 7551, 7341\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 8141, 8221\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 8041, 8131\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 8451, 8511\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 8191, 8261\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 8291, 8371\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 8291, 8371\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 8231, 8051\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 8041, 8131\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 8321, 8391\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 8321, 8391\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 8361, 8441\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 7691, 7811\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n"
     ]
    }
   ],
   "source": [
    "# Convert the .img masks to .TIF masks\n",
    "folders = sorted(os.listdir(\"./unzipped/\"))\n",
    "folders = [f for f in folders if '.' not in f]  # Filter out .gitignore\n",
    "for folder in folders:\n",
    "    products = sorted(os.listdir(\"./unzipped/\" + folder + \"/BC/\"))\n",
    "    for product in products:\n",
    "        img_path  = \"./unzipped/\" + folder + \"/BC/\" + product + \"/\" + product + \"_fixedmask.img\"\n",
    "        gtiff_path = \"./unzipped/\" + folder + \"/BC/\" + product + \"/\" + product + \"_fixedmask.TIF\"\n",
    "        !gdal_translate -of GTiff {img_path + \" \" + gtiff_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move to raw data folder\n",
    "# assuming this file is 1 folder lower in project folder\n",
    "project_path = \"/home/mxh/RS-Net/\"\n",
    "!cp -R ./unzipped/* {project_path + 'data/raw/landsat8ccv/'}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "satellite-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
